{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18a3191d",
   "metadata": {},
   "source": [
    "\n",
    "# Cross Validation with Linear Regression — **Solutions**\n",
    "\n",
    "This notebook contains **worked solutions** for the three exercises on cross-validation using **Linear Regression** in scikit-learn.  \n",
    "The code follows best practices: Pipelines, `KFold`, and RMSE as the metric. Plots are generated with matplotlib (no custom styles).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475d8918",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===== Setup (Run once) =====\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# scikit-learn uses negative RMSE for scoring to keep \"higher is better\"\n",
    "RMSE_SCORING = \"neg_root_mean_squared_error\"\n",
    "\n",
    "# Load data\n",
    "data = load_diabetes()\n",
    "X = data.data          # shape (442, 10)\n",
    "y = data.target        # quantitative target\n",
    "\n",
    "# Optional: peek at the data\n",
    "pd.DataFrame(X, columns=data.feature_names).head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2910e953",
   "metadata": {},
   "source": [
    "\n",
    "## Exercise 1 — Train/Test Split vs. K-Fold Cross-Validation (Solution)\n",
    "\n",
    "**Goal:** Compare an 80/20 train–test split to a 5-fold CV estimate with Linear Regression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7d816b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Part A: 80/20 split RMSE ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "pipe = Pipeline(steps=[(\"scaler\", StandardScaler()), (\"lr\", LinearRegression())])\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "rmse_split = np.sqrt(np.mean((y_test - y_pred) ** 2))\n",
    "print(f\"Test RMSE (single 80/20 split): {rmse_split:.2f}\")\n",
    "\n",
    "# --- Part B: 5-fold CV RMSE ---\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(pipe, X, y, scoring=RMSE_SCORING, cv=kf)\n",
    "\n",
    "rmses = -scores\n",
    "mean_rmse = rmses.mean()\n",
    "std_rmse = rmses.std()\n",
    "print(f\"CV RMSE (5-fold): {mean_rmse:.2f} ± {std_rmse:.2f}\")\n",
    "print(\"Fold RMSEs:\", np.round(rmses, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d98bb35",
   "metadata": {},
   "source": [
    "\n",
    "**Why CV is often more reliable:**  \n",
    "A single train/test split uses only one partition of the data, so its error estimate can be **high-variance** and sensitive to how the data happened to split.  \n",
    "**K-fold cross-validation** averages performance across multiple splits (folds), reducing variance and giving a **more stable, reliable estimate** of out-of-sample error. In small-to-moderate datasets (like `load_diabetes`), this stability is especially valuable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c4daee",
   "metadata": {},
   "source": [
    "\n",
    "## Exercise 2 — How Many Features Help? (Feature Count vs. CV Error) — Solution\n",
    "\n",
    "We evaluate `k ∈ {2, 4, 6, 8, 10}` features using the same pipeline and 5-fold CV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8424975e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "k_values = [2, 4, 6, 8, 10]\n",
    "mean_rmses, std_rmses = [], []\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "rows = []\n",
    "for k in k_values:\n",
    "    Xk = X[:, :k]  # use first k features\n",
    "    pipe = Pipeline([(\"scaler\", StandardScaler()), (\"lr\", LinearRegression())])\n",
    "    scores = cross_val_score(pipe, Xk, y, scoring=RMSE_SCORING, cv=kf)\n",
    "    rmses = -scores\n",
    "    mean_rmses.append(rmses.mean())\n",
    "    std_rmses.append(rmses.std())\n",
    "    rows.append({\"k_features\": k, \"mean_RMSE\": rmses.mean(), \"std_RMSE\": rmses.std()})\n",
    "\n",
    "results_df = pd.DataFrame(rows)\n",
    "print(results_df)\n",
    "\n",
    "# Plot (matplotlib, no custom styles/colors)\n",
    "plt.figure()\n",
    "plt.errorbar(k_values, mean_rmses, yerr=std_rmses, fmt='o-')\n",
    "plt.xlabel(\"Number of features (k)\")\n",
    "plt.ylabel(\"CV RMSE (5-fold)\")\n",
    "plt.title(\"Effect of Feature Count on CV Error\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b666adb9",
   "metadata": {},
   "source": [
    "\n",
    "**Interpretation:**  \n",
    "- Adding features can **help at first** by capturing more signal (lower bias).  \n",
    "- After some point, extra features may add **noise** or redundancy, and the model can become less stable, so CV RMSE may **plateau or even worsen**.  \n",
    "- The best `k` is the one that **minimizes CV RMSE**, not necessarily “all features.”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5da8a9b",
   "metadata": {},
   "source": [
    "\n",
    "## Exercise 3 — Linear Model Complexity via Polynomial Features — Solution\n",
    "\n",
    "We keep a Linear Regression model but expand inputs via `PolynomialFeatures(degree=d)` for `d ∈ {1, 2, 3}` on the **first 2 features** only.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a6c613",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "degrees = [1, 2, 3]\n",
    "mean_rmses_deg, std_rmses_deg = [], []\n",
    "\n",
    "X2 = X[:, :2]\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "rows_poly = []\n",
    "for d in degrees:\n",
    "    pipe = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"poly\", PolynomialFeatures(degree=d, include_bias=False)),\n",
    "        (\"lr\", LinearRegression())\n",
    "    ])\n",
    "    scores = cross_val_score(pipe, X2, y, scoring=RMSE_SCORING, cv=kf)\n",
    "    rmses = -scores\n",
    "    mean_rmses_deg.append(rmses.mean())\n",
    "    std_rmses_deg.append(rmses.std())\n",
    "    rows_poly.append({\"degree\": d, \"mean_RMSE\": rmses.mean(), \"std_RMSE\": rmses.std()})\n",
    "\n",
    "poly_df = pd.DataFrame(rows_poly)\n",
    "print(poly_df)\n",
    "\n",
    "# Plot (matplotlib, no custom colors/styles)\n",
    "plt.figure()\n",
    "plt.errorbar(degrees, mean_rmses_deg, yerr=std_rmses_deg, fmt='o-')\n",
    "plt.xlabel(\"Polynomial degree\")\n",
    "plt.ylabel(\"CV RMSE (5-fold)\")\n",
    "plt.title(\"Polynomial Features vs. CV Error (Linear Regression)\")\n",
    "plt.xticks(degrees)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ec6e66",
   "metadata": {},
   "source": [
    "\n",
    "**Interpretation:**  \n",
    "- `degree = 1` is the baseline linear model.  \n",
    "- `degree = 2` can improve fit if there are **nonlinear relationships** in the first two features.  \n",
    "- `degree = 3` increases flexibility further and may **overfit**, which often shows up as **higher CV RMSE** than `degree = 2`.  \n",
    "- Cross-validation helps identify the **sweet spot** where added complexity improves generalization rather than harming it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6af8b2b",
   "metadata": {},
   "source": [
    "\n",
    "### (Optional) Extension — Fold Diagnostics\n",
    "\n",
    "Checking fold-by-fold RMSE can reveal variance across splits:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00669f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "pipe = Pipeline([(\"scaler\", StandardScaler()), (\"lr\", LinearRegression())])\n",
    "scores = cross_val_score(pipe, X[:, :10], y, scoring=RMSE_SCORING, cv=kf)\n",
    "print(\"Fold RMSEs:\", -scores)\n",
    "print(\"Mean ± SD:\", (-scores).mean(), \"±\", (-scores).std())\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
